{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the DECiSION model to predict segmentation maps\n",
    "Use a trained U-Net model created by `DECiSION_train.ipynb` to produce segmentation maps for MRI images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DECiSION_settings as settings\n",
    "from thesis_common import read_images, read_groundtruths, convert_pred_to_img, group_images,\\\n",
    "    show_image, create_hdf5_db, convert_img_to_pred\n",
    "from thesis_metric_loss import evaluate_model, dice_coef,\\\n",
    "    weighted_pixelwise_crossentropy_loss\n",
    "\n",
    "from dltoolkit.utils.generic import list_images\n",
    "from dltoolkit.nn.segment import UNet_NN\n",
    "from dltoolkit.utils.visual import plot_roc_curve, plot_precision_recall_curve,\\\n",
    "    print_confusion_matrix, print_classification_report\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "    \n",
    "import os, cv2, shutil, time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine test/inference settings\n",
    "Set `IS_INFERENCE` to `False` to create segmentation maps for test MRI images for which ground truths **are** available. This is typically used to obtain a final test error estimate at the very end of the training process. Set it to `False` to use a trained model for MRI images for which ground truths are not available, i.e. simulating a production scenario.\n",
    "\n",
    "During development set `IS_DEVELOPMENT` to `True` to always use the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_INFERENCE = False\n",
    "IS_DEVELOPMENT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to the trained model to load\n",
    "Enter the full path to the saved trained model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_NAME = \"../savedmodels/DECiSION_UNet_brain_3layer_BN_ep100.model\"\n",
    "# TRAINED_MODEL_NAME = \"../savedmodels/DECiSION_UNet_brain_4layer_BN_ep100.model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert test data to HDF5\n",
    "The first function `perform_hdf5_conversion_test()` converts data in the `test` folder to HDF5. Data comprises MRI images as well as their ground truths. This function is used to apply a trained model to MRI images for which ground truths are available so that various performance metrics can be calculated.\n",
    "\n",
    "The second function `perform_hdf5_conversion_inference()` does the same but does not include ground truths. It is used to apply a trained model to MRI images for which ground truths are not available, e.g. in a production environment.\n",
    "\n",
    "**Note**: during development and pipeline testing neither function is used. Instead, the training/validation set is used, the same sets used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hdf5_conversion_test(settings):\n",
    "    # Prepare the path to the TEST images AND ground truths. Note that the data is NOT shuffled.\n",
    "    img_path = os.path.join(settings.TEST_PATH, settings.FLDR_IMAGES)\n",
    "    msk_path = os.path.join(settings.TEST_PATH, settings.FLDR_GROUND_TRUTH)\n",
    "\n",
    "    # Create a list of paths to the individual patient folders\n",
    "    patient_fld_imgs = sorted([os.path.join(img_path, e.name)\n",
    "                               for e in os.scandir(img_path) if e.is_dir()])\n",
    "    patient_fld_masks = sorted([os.path.join(msk_path, e.name)\n",
    "                                for e in os.scandir(msk_path) if e.is_dir()])\n",
    "\n",
    "    # Obtain a list of paths to the test images and ground truths for each patient\n",
    "    img_list = []\n",
    "    msk_list = []\n",
    "    for patient_ix, (p_fld_imgs, p_fld_masks) in enumerate(zip(patient_fld_imgs,\n",
    "                                                               patient_fld_masks)):\n",
    "        img_list.extend(sorted(list(list_images(basePath=p_fld_imgs,\n",
    "                                                validExts=settings.IMG_EXTENSION)))\n",
    "                        [settings.SLICE_START:settings.SLICE_END])\n",
    "        msk_list.extend(sorted(list(list_images(basePath=p_fld_masks,\n",
    "                                                validExts=settings.IMG_EXTENSION)))\n",
    "                        [settings.SLICE_START:settings.SLICE_END])\n",
    "\n",
    "    # Create the HDF5 data sets\n",
    "    output_paths = []\n",
    "\n",
    "    # Test images\n",
    "    output_paths.append(create_hdf5_db(img_list, \"test\", img_path,\n",
    "                                       (settings.IMG_HEIGHT,\n",
    "                                        settings.IMG_WIDTH,\n",
    "                                        settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY,\n",
    "                                       ext=settings.HDF5_EXT,\n",
    "                                       settings=settings))\n",
    "\n",
    "    # Test ground truths\n",
    "    output_paths.append(create_hdf5_db(msk_list, \"test\", msk_path,\n",
    "                                       (settings.IMG_HEIGHT,\n",
    "                                        settings.IMG_WIDTH,\n",
    "                                        settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY,\n",
    "                                       ext=settings.HDF5_EXT,\n",
    "                                       settings=settings,\n",
    "                                       is_mask=True))\n",
    "    \n",
    "    return output_paths\n",
    "\n",
    "def perform_hdf5_conversion_inference(settings):\n",
    "    # Prepare the path to the TEST images (NO ground truths because they are not available)\n",
    "    test_path = os.path.join(settings.TEST_PATH, settings.FLDR_IMAGES)\n",
    "\n",
    "    # Create a list of paths to the individual patient folders\n",
    "    test_imgs = sorted(list(list_images(basePath=test_path,\n",
    "                                        validExts=settings.IMG_EXTENSION)))[settings.SLICE_START:settings.SLICE_END]\n",
    "\n",
    "    # Create the HDF5 data sets\n",
    "    output_paths = []\n",
    "\n",
    "    # Test images (no ground truths available, no need to split). The assumption is only\n",
    "    # relevant images are placed in the test folder, i.e. the pipeline will not exclude\n",
    "    # any slices\n",
    "    output_paths.append(create_hdf5_db(test_imgs, \"test\", test_path,\n",
    "                                       (settings.IMG_HEIGHT,\n",
    "                                        settings.IMG_WIDTH,\n",
    "                                        settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY,\n",
    "                                       ext=settings.HDF5_EXT,\n",
    "                                       settings=settings))\n",
    "\n",
    "    return output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_DEVELOPMENT:\n",
    "    print(\"Development mode, no test set created. Using the training/validation set.\")\n",
    "else:\n",
    "    if IS_INFERENCE:\n",
    "        output_paths = perform_hdf5_conversion_inference(settings)\n",
    "        print(\"Converted test images WITHOUT ground truths: {}\".format(output_paths))\n",
    "    else:\n",
    "        output_paths = perform_hdf5_conversion_test(settings)\n",
    "        print(\"Converted test images WITH ground truths: {}\".format(output_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The cell below performs the actual loading of data. The assumption is that all test data fits into memory, generators are NOT used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images and ground truths\n",
    "if IS_DEVELOPMENT:\n",
    "    # Use training images for pipeline validation and training\n",
    "    print(\"WARNING: using TRAINING images, NOT TEST images for PIPELINE DEVELOPMENT\")\n",
    "    test_imgs = read_images(\"../data/MSC8002/training/train_images.h5\",\n",
    "                            settings.HDF5_KEY)\n",
    "    test_ground_truths = read_groundtruths(\"../data/MSC8002/training/train_groundtruths.h5\",\n",
    "                                           settings.HDF5_KEY)\n",
    "else:\n",
    "    if IS_INFERENCE:\n",
    "        print(\"--- Pre-processing test images without ground truths for INFERENCE\")\n",
    "        # Use for inference on test images without ground truths\n",
    "        test_imgs = read_images(output_paths[0], settings.HDF5_KEY)\n",
    "    else:\n",
    "        # Use test images WITH ground truths for final model evaluation\n",
    "        print(\"WARNING: using TEST images, NOT TRAINING images for MODEL EVALUATION\")\n",
    "        test_imgs = read_images(output_paths[0], settings.HDF5_KEY)\n",
    "        test_ground_truths = read_groundtruths(output_paths[1], settings.HDF5_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show one image to check\n",
    "Show a single image and, if available, its ground truth just as a check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IX = 0\n",
    "\n",
    "show_image(np.squeeze(test_imgs[IX]), 'Example image')\n",
    "print(\"       Max image intensity: {} - {} - {}\".format(np.max(test_imgs[IX]),\n",
    "                                                        test_imgs.dtype,\n",
    "                                                        test_imgs.shape))\n",
    "\n",
    "if not IS_INFERENCE or IS_DEVELOPMENT:\n",
    "    show_image(np.squeeze(test_ground_truths[IX]), 'Example ground truth')\n",
    "    print(\"Max ground truth intensity: {} - {} - {}\".format(np.max(test_ground_truths[IX]),\n",
    "                                                            test_ground_truths.dtype,\n",
    "                                                            test_ground_truths.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model\n",
    "Load the saved model located in the location specified by `TRAINED_MODEL_NAME`. Use the same `build_model_XXX()` method that was used by `DECIiSION_training.ipynb` to train the model. Keras is unable to load a model when a different architecture has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the UNet model and load its saved weights\n",
    "unet = UNet_NN(img_height=settings.IMG_HEIGHT,\n",
    "               img_width=settings.IMG_WIDTH,\n",
    "               img_channels=settings.IMG_CHANNELS,\n",
    "               num_classes=settings.NUM_CLASSES)\n",
    "model = unet.build_model_BRAIN_3layer(use_bn=True, use_dropout=False)\n",
    "# model = unet.build_model_BRAIN_4layer(use_bn=True, use_dropout=False)\n",
    "model.load_weights(TRAINED_MODEL_NAME)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce segmentation maps\n",
    "Predict segmentation maps for all MRI images in the `test_imgs` array and calculate overall loss and metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Number of samples: {}\".format(test_imgs.shape))\n",
    "predictions = model.predict(test_imgs, batch_size=settings.TRN_BATCH_SIZE, verbose=2)\n",
    "print(\"Elapsed time: {:.2f}s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = evaluate_model(model, test_imgs, test_ground_truths,\n",
    "                           Adam(amsgrad=True), weighted_pixelwise_crossentropy_loss,\n",
    "                           dice_coef, convert_img_to_pred, settings)\n",
    "\n",
    "for name, val in (zip(model.metrics_names, eval_list)):\n",
    "    print(\"{} = {:.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert predictions to segmentation map images\n",
    "Convert the predictions (i.e. scores for both classes for each pixel) to a shape that can be displayed later. A threshold `TRN_PRED_THRESHOLD` is used to determine whether a pixel should be assigned the background or blood vessel class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_imgs = convert_pred_to_img(predictions,\n",
    "                                       threshold=settings.TRN_PRED_THRESHOLD,\n",
    "                                       verbose=settings.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show/save segmentation maps\n",
    "Display a single MRI image, its ground truth (if available) and the predicted segmentation map. In addition, save a number of images, ground truths and segmentation maps into a single image (one for each type) for visualization and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a single image, ground truth and segmentation map\n",
    "MAX_IMAGES = len(predictions_imgs)\n",
    "show_image(np.squeeze(test_imgs[0]), 'Original image')\n",
    "show_image(np.squeeze(predictions_imgs[0]), 'Segmentation map')\n",
    "\n",
    "if not IS_INFERENCE or IS_DEVELOPMENT:\n",
    "    show_image(np.squeeze(test_ground_truths[0]), 'Ground truth')\n",
    "\n",
    "    # Plot a number of ground truths in a single image \n",
    "    group_images(test_ground_truths[0:min(16, MAX_IMAGES)],\n",
    "                 4, 1.0, False, \"../output/DECISION_\"+unet.title+\"_grp_groundtruths\")\n",
    "    \n",
    "    print(\"  gr truth {} dtype {}\".format(np.max(test_ground_truths[0]),\n",
    "                                          test_ground_truths[0].dtype))\n",
    "\n",
    "# Plot images and segmentation maps in a single image each\n",
    "group_images(test_imgs[0:min(16, MAX_IMAGES)],\n",
    "             4, 1.0, False, \"../output/DECISION_\" + unet.title+\"_grp_images\")\n",
    "group_images(predictions_imgs[0:min(16, MAX_IMAGES)],\n",
    "             4, 1.0, False, \"../output/DECISION_\" + unet.title+\"_grp_predictions\")\n",
    "\n",
    "print(\"  original {} dtype {}\".format(np.max(test_imgs[0]), test_imgs[0].dtype))\n",
    "print(\"prediction {} dtype {}\".format(np.max(predictions_imgs[0]), predictions_imgs[0].dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show metrics\n",
    "The cells below produxe a number of metrics for the current model and the segmentation maps it produced. This is not possible when ground truths are not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve\n",
    "Plot the Receiver Operator Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_INFERENCE or IS_DEVELOPMENT:\n",
    "    roc_path = os.path.join(settings.OUTPUT_PATH, \"DECiSION_\" + unet.title)\n",
    "    plot_roc_curve(test_ground_truths, predictions[:,:,:,1], show=True, save_path=roc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision/Recall curve\n",
    "Plot the Precision/Recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_INFERENCE or IS_DEVELOPMENT:\n",
    "    prec_path = os.path.join(settings.OUTPUT_PATH, \"DECiSION_\" + unet.title)\n",
    "    plot_precision_recall_curve(test_ground_truths,\n",
    "                                predictions,\n",
    "                                settings.NUM_CLASSES,\n",
    "                                show=True,\n",
    "                                save_path=prec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "Plot the pixel wise confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_INFERENCE or IS_DEVELOPMENT:\n",
    "    (conf_ind, conf_mat) = print_confusion_matrix(test_ground_truths, predictions_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report\n",
    "Plot the pixel wise classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_INFERENCE or IS_DEVELOPMENT:\n",
    "    print_classification_report(test_ground_truths, predictions_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write segmentation maps, ground truths and MRI images to disk\n",
    "Save the predicted segmentation maps, ground truths (after applying the binary mask) and original MRI images to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove existing files\n",
    "if os.path.exists(settings.SEGMAP_PATH):\n",
    "    shutil.rmtree(settings.SEGMAP_PATH)\n",
    "os.makedirs(settings.SEGMAP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions_imgs)):\n",
    "    cv2.imwrite(settings.SEGMAP_PATH + \"DECiSION_segmap_{}.jpg\".format(i),\n",
    "                predictions_imgs[i],\n",
    "                (cv2.IMWRITE_JPEG_QUALITY, 100))\n",
    "    \n",
    "if not IS_INFERENCE or IS_DEVELOPMENT:\n",
    "    for i in range(len(test_ground_truths)):\n",
    "        cv2.imwrite(settings.SEGMAP_PATH + \"DECiSION_groundtruth_{}.jpg\".format(i),\n",
    "                    test_ground_truths[i],\n",
    "                    (cv2.IMWRITE_JPEG_QUALITY, 100))\n",
    "        \n",
    "for i in range(len(test_imgs)):\n",
    "    cv2.imwrite(settings.SEGMAP_PATH + \"DECiSION_image_{}.jpg\".format(i),\n",
    "                test_imgs[i].astype(np.float32)*255,\n",
    "                (cv2.IMWRITE_JPEG_QUALITY, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing/inference complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
