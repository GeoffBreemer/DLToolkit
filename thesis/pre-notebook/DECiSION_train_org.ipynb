{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DECiSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set seeds and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "from numpy.random import seed\n",
    "seed(RANDOM_STATE)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(RANDOM_STATE)\n",
    "\n",
    "import random\n",
    "random.seed = RANDOM_STATE\n",
    "\n",
    "import DECiSION_settings as settings\n",
    "\n",
    "from dltoolkit.utils.generic import model_architecture_to_file, model_summary_to_file, list_images\n",
    "from dltoolkit.utils.image import standardise, standardise_single, mean_subtraction\n",
    "from dltoolkit.nn.segment import UNet_NN\n",
    "from dltoolkit.utils.visual import plot_training_history\n",
    "from dltoolkit.iomisc import HDF5Writer, HDF5Reader, HDF5Generator_Segment\n",
    "\n",
    "from thesis_common import convert_img_to_pred, convert_pred_to_img, group_images\n",
    "from thesis_metric_loss import dice_coef, weighted_pixelwise_crossentropy_loss\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os, cv2, time, progressbar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5_db(imgs_list, dn_name, img_path, img_shape, key, ext, settings, is_mask=False):\n",
    "    \"\"\"\n",
    "    Create a HDF5 file using a list of paths to individual images to be written to the data set\n",
    "    :param imgs_list: list of image paths\n",
    "    :param dn_name: becomes part of the HDF5 file name\n",
    "    :param img_path: path to the location of the `images` and `groundtruths` subfolders\n",
    "    :param img_shape: shape of the images being written to the data set\n",
    "    :param key: key to use for the data set\n",
    "    :param ext: extension of the HDF5 file name\n",
    "    :param settings: holds settings\n",
    "    :param is_mask: True if masks are being written, False if not\n",
    "    :return: the full path to the HDF5 file\n",
    "    \"\"\"\n",
    "    # Construct the name of the database\n",
    "    tmp_name = dn_name + (\"_masks\" if is_mask else \"_imgs\")\n",
    "    output_path = os.path.join(os.path.dirname(img_path), tmp_name) + ext\n",
    "    print(output_path)\n",
    "\n",
    "    # Prepare the HDF5 writer, which expects a label vector. Because this is a segmentation problem just pass None\n",
    "    # hdf5_writer = HDF5Writer((len(imgs_list), img_shape[0], img_shape[1], img_shape[2]), output_path,\n",
    "    hdf5_writer = HDF5Writer(((len(imgs_list),) + img_shape),\n",
    "                             output_path=output_path,\n",
    "                             feat_key=key,\n",
    "                             label_key=None,\n",
    "                             del_existing=True,\n",
    "                             buf_size=len(imgs_list),\n",
    "                             dtype_feat=np.float32 if not is_mask else np.uint8\n",
    "                             )\n",
    "\n",
    "    classcounts = [0] * settings.NUM_CLASSES\n",
    "\n",
    "    # Loop through all images\n",
    "    widgets = [\"Creating HDF5 database \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "    pbar = progressbar.ProgressBar(maxval=len(imgs_list), widgets=widgets).start()\n",
    "    for i, img in enumerate(imgs_list):\n",
    "        image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Apply binary thresholding to ground truth masks\n",
    "        if is_mask:\n",
    "            _, image = cv2.threshold(image, settings.MASK_BINARY_THRESHOLD, settings.MASK_BLOODVESSEL, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Convert to the format produced by the model\n",
    "            # print(image.shape)\n",
    "            # print(np.array([image]).shape)\n",
    "            # image = convert_img_to_pred(np.array([image]), settings, settings.VERBOSE)\n",
    "\n",
    "            for ix, cl in enumerate([settings.MASK_BACKGROUND, settings.MASK_BLOODVESSEL]):\n",
    "                classcounts[ix] += len(np.where(image == cl)[0])\n",
    "        else:\n",
    "            # Apply preprocessing to images (not to ground truth masks)\n",
    "            # print(\"before, min {} max {}\".format(np.min(image), np.max(image)))\n",
    "            # print(\"Max prior: {}\".format(np.max(image)))\n",
    "            # image = standardise_single(image)\n",
    "            # image = mean_subtraction(image)\n",
    "            # print(\"Max after: {}\".format(np.max(image)))\n",
    "            # print(\" after, min {} max {}\".format(np.min(image), np.max(image)))\n",
    "            pass\n",
    "\n",
    "        # Reshape from (height, width) to (height, width, 1)\n",
    "        image = image.reshape((img_shape[0], img_shape[1], img_shape[2]))\n",
    "\n",
    "        if not is_mask:\n",
    "        #     image = standardise_single(image)\n",
    "            image = mean_subtraction(image)\n",
    "            # image=image/255.\n",
    "\n",
    "        hdf5_writer.add([image], None)\n",
    "        pbar.update(i)\n",
    "\n",
    "    if is_mask:\n",
    "        total = sum(classcounts)\n",
    "        for i in range(settings.NUM_CLASSES):\n",
    "            classcounts[i] = int(total / classcounts[i])\n",
    "\n",
    "    pbar.finish()\n",
    "    hdf5_writer.close()\n",
    "\n",
    "    if is_mask:\n",
    "        return output_path#, classcounts\n",
    "    else:\n",
    "        return output_path\n",
    "\n",
    "\n",
    "def perform_hdf5_conversion(settings):\n",
    "    # Prepare the path to the training images and ground truths\n",
    "    img_exts = \".jpg\"\n",
    "    img_path = os.path.join(settings.TRAINING_PATH, settings.FLDR_IMAGES)\n",
    "    msk_path = os.path.join(settings.TRAINING_PATH, settings.FLDR_GROUND_TRUTH)\n",
    "    test_path = os.path.join(settings.TEST_PATH, settings.FLDR_IMAGES)\n",
    "\n",
    "    # Create a list of paths to the individual patient folders\n",
    "    patient_fld_imgs = sorted([os.path.join(img_path, e.name) for e in os.scandir(img_path) if e.is_dir()])\n",
    "    patient_fld_masks = sorted([os.path.join(msk_path, e.name) for e in os.scandir(msk_path) if e.is_dir()])\n",
    "    test_imgs = sorted(list(list_images(basePath=test_path, validExts=img_exts)))\n",
    "\n",
    "    # Obtain a list of paths to the training images and ground truths for each patient\n",
    "    img_list = []\n",
    "    msk_list = []\n",
    "    for patient_ix, (p_fld_imgs, p_fld_masks) in enumerate(zip(patient_fld_imgs, patient_fld_masks)):\n",
    "        img_list.extend(sorted(list(list_images(basePath=p_fld_imgs,\n",
    "                                                validExts=img_exts)))\n",
    "                        [settings.SLICE_START:settings.SLICE_END])\n",
    "        msk_list.extend(sorted(list(list_images(basePath=p_fld_masks,\n",
    "                                                validExts=img_exts)))\n",
    "                        [settings.SLICE_START:settings.SLICE_END])\n",
    "\n",
    "    assert(len(img_list) == len(msk_list))\n",
    "\n",
    "    # Split the training set into a training and validation set\n",
    "    train_img, val_img, train_msk, val_msk = train_test_split(img_list, msk_list,\n",
    "                                                              test_size=settings.TRN_TRAIN_VAL_SPLIT,\n",
    "                                                              random_state=settings.RANDOM_STATE,\n",
    "                                                              shuffle=True)\n",
    "\n",
    "    print(\"Check train data: {} = {}\".format(train_img[0], train_msk[0]))\n",
    "    print(\"  Check val data: {} = {}\".format(val_img[0], val_msk[0]))\n",
    "    print(\"Num train: {}, num val: {}\".format(len(train_img), len(val_img)))\n",
    "\n",
    "    # Create the HDF5 data sets\n",
    "    output_paths = []\n",
    "\n",
    "    # Training images\n",
    "    output_paths.append(create_hdf5_db(train_img, \"train\", img_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings))\n",
    "\n",
    "    # Training ground truths\n",
    "    output_paths.append(create_hdf5_db(train_msk, \"train\", msk_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings,\n",
    "                                       is_mask=True))\n",
    "\n",
    "    # Validation images\n",
    "    output_paths.append(create_hdf5_db(val_img, \"val\", img_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings))\n",
    "\n",
    "    # Validation ground truths\n",
    "    output_paths.append(create_hdf5_db(val_msk, \"val\", msk_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings,\n",
    "                                       is_mask=True))\n",
    "\n",
    "    # Test images (no ground truths available, no need to split)\n",
    "    output_paths.append(create_hdf5_db(test_imgs, \"test\", test_path,\n",
    "                                        (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                        key=settings.HDF5_KEY, ext=settings.HDF5_EXT,\n",
    "                                        settings=settings))\n",
    "\n",
    "    return output_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, title):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocess_image(image_path, key, is_3D=False):\n",
    "    \"\"\"Perform image pre-processing, resulting pixel values are between 0.0 and 1.0\"\"\"\n",
    "    imgs = HDF5Reader().load_hdf5(image_path, key)\n",
    "    print(\"Loading image HDF5: {} with dtype = {}\\n\".format(image_path, imgs.dtype))\n",
    "\n",
    "    # Permute array dimensions for the 3D U-Net model so that the shape becomes: (-1, height, width, slices, channels)\n",
    "    if is_3D:\n",
    "        # Standardise\n",
    "        # print(\"prior group std during READ:{} - {}\".format(imgs.shape, imgs.dtype))\n",
    "        imgs = standardise(imgs)\n",
    "        # imgs = mean_subtraction(imgs)\n",
    "        # print(\"after group std during READ:{} - {}\".format(imgs.shape, imgs.dtype))\n",
    "\n",
    "        imgs = np.transpose(imgs, axes=(0, 2, 3, 1, 4))\n",
    "\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def read_preprocess_groundtruth(ground_truth_path, key, is_3D=False):\n",
    "    \"\"\"Perform ground truth image pre-processing, resulting pixel values are between 0 and 255\"\"\"\n",
    "    imgs = HDF5Reader().load_hdf5(ground_truth_path, key).astype(\"uint8\")\n",
    "    print(\"Loading ground truth HDF5: {} with dtype = {}\\n\".format(ground_truth_path, imgs.dtype))\n",
    "\n",
    "    # Permute array dimensions for the 3D U-Net model so that the shape becomes: (-1, height, width, slices, channels)\n",
    "    if is_3D:\n",
    "        imgs = np.transpose(imgs, axes=(0, 2, 3, 1, 4))\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image files to HDF5\n",
    "if settings.IS_DEVELOPMENT:\n",
    "    print(\"\\n--- Converting images to HDF5\")\n",
    "    hdf5_paths = perform_hdf5_conversion(settings)\n",
    "else:\n",
    "    # During development avoid performing HDF5 conversion for every run\n",
    "    hdf5_paths = [\"../data/MSC8002/training/train_imgs.h5\",\n",
    "                  \"../data/MSC8002/training/train_masks.h5\",\n",
    "                  \"../data/MSC8002/training/val_imgs.h5\",\n",
    "                  \"../data/MSC8002/training/val_masks.h5\"\n",
    "                  \"../data/MSC8002/test/test_imgs.h5\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training images and ground truths\n",
    "print(\"\\n--- Read and preprocess images\")\n",
    "train_imgs = read_preprocess_image(hdf5_paths[0], settings.HDF5_KEY)\n",
    "train_grndtr = read_preprocess_groundtruth(hdf5_paths[1], settings.HDF5_KEY)\n",
    "val_imgs = read_preprocess_image(hdf5_paths[2], settings.HDF5_KEY)\n",
    "val_grndtr = read_preprocess_groundtruth(hdf5_paths[3], settings.HDF5_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show an image as a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one image plus its ground truth as a quick check\n",
    "print(\"\\n--- Show TRAIN example image\")\n",
    "IX = 0\n",
    "\n",
    "show_image(np.squeeze(train_imgs[IX]), title=\"Training image\")\n",
    "show_image(np.squeeze(train_grndtr[IX]), title=\"Training ground truth\")\n",
    "print(\"Max image intensity: {} - {} - {} - {}\".format(np.max(train_imgs[IX]), np.min(train_imgs[IX]),\n",
    "                                                      train_imgs.dtype, train_imgs.shape))\n",
    "print(\"Max grtrh intensity: {} - {} - {} - {}\".format(np.max(train_grndtr[IX]), np.min(train_grndtr[IX]),\n",
    "                                                      train_grndtr.dtype, train_grndtr.shape))\n",
    "\n",
    "print(\"\\n--- Show VAL example image\")\n",
    "IX = 0\n",
    "show_image(np.squeeze(val_imgs[IX]), title=\"Validation image\")\n",
    "show_image(np.squeeze(val_grndtr[IX]), title=\"Validation ground truth\")\n",
    "print(\"Max image intensity: {} min: {} - {} - {}\".format(np.max(train_imgs[IX]), np.min(train_imgs[IX]),\n",
    "                                                         val_imgs.dtype, val_imgs.shape))\n",
    "print(\"Max grtrh intensity: {} min: {} - {} - {}\".format(np.max(train_grndtr[IX]), np.min(train_grndtr[IX]),\n",
    "                                                         val_grndtr.dtype, val_grndtr.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print class distribution\n",
    "class_weights = [settings.CLASS_WEIGHT_BACKGROUND, settings.CLASS_WEIGHT_BLOODVESSEL]\n",
    "print(\"Class distribution: {}\".format(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the U-Net model\n",
    "unet = UNet_NN(img_height=settings.IMG_HEIGHT,\n",
    "               img_width=settings.IMG_WIDTH,\n",
    "               img_channels=settings.IMG_CHANNELS,\n",
    "               num_classes=settings.NUM_CLASSES)\n",
    "\n",
    "# model = unet.build_model_sigmoid()\n",
    "# model = unet.build_model_flatten()\n",
    "model = unet.build_model_softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare some path strings\n",
    "model_path = os.path.join(settings.MODEL_PATH, \"DECiSION_\" + unet.title + \"_ep{}.model\".format(settings.TRN_NUM_EPOCH))\n",
    "summ_path = os.path.join(settings.OUTPUT_PATH, \"DECiSION_\" + unet.title + \"_model_summary.txt\")\n",
    "csv_path = os.path.join(settings.OUTPUT_PATH, \"DECiSION_\" + unet.title + \"_training_ep{}_bs{}.csv\".format(settings.TRN_NUM_EPOCH,\n",
    "                                                                                            settings.TRN_BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/print model architecture information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the architecture to the console, a text file and an image\n",
    "model.summary()\n",
    "model_summary_to_file(model, summ_path)\n",
    "model_architecture_to_file(unet.model, settings.OUTPUT_PATH + \"DECiSION_\" + unet.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ground truths into the same shape as the predictions the U-net produces\n",
    "print(\"--- \\nEncoding training ground truths\")\n",
    "print(\"Ground truth shape before conversion: {} of type {}\".format(train_grndtr.shape, train_grndtr.dtype))\n",
    "# train_grndtr_ext_conv = train_grndtr        # no conversion for sigmoid\n",
    "# val_grndtr_ext_conv = val_grndtr        # no conversion for sigmoid\n",
    "\n",
    "# train_grndtr_ext_conv = convert_img_to_pred_flatten(train_grndtr, settings, settings.VERBOSE)  # softmax: 3D\n",
    "# val_grndtr_ext_conv = convert_img_to_pred_flatten(val_grndtr, settings, settings.VERBOSE)  # softmax: 3D\n",
    "\n",
    "train_grndtr_ext_conv = convert_img_to_pred(train_grndtr, settings, settings.VERBOSE)  # softmax: 4D\n",
    "val_grndtr_ext_conv = convert_img_to_pred(val_grndtr, settings, settings.VERBOSE)  # softmax: 4D\n",
    "print(\" Ground truth shape AFTER conversion: {} of type {}\\n\".format(train_grndtr_ext_conv.shape, train_grndtr_ext_conv.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\n--- Start training\")\n",
    "# Prepare callbacks\n",
    "callbacks = [ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "             EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=0,\n",
    "                           patience=settings.TRN_EARLY_PATIENCE,\n",
    "                           verbose=0,\n",
    "                           mode=\"auto\"),\n",
    "             CSVLogger(csv_path, append=False),\n",
    "             ]\n",
    "\n",
    "# Set the optimiser, loss function and metrics\n",
    "# opt = Adam()\n",
    "# metrics = [dice_coef]\n",
    "# loss = \"binary_crossentropy\"\n",
    "opt = Adam()\n",
    "metrics = [dice_coef]\n",
    "loss = weighted_pixelwise_crossentropy_loss(class_weights)\n",
    "\n",
    "# Compile and fit\n",
    "model.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with all data in memory\n",
    "start_time = time.time()\n",
    "hist = model.fit(train_imgs, train_grndtr_ext_conv,\n",
    "                 epochs=settings.TRN_NUM_EPOCH,\n",
    "                 batch_size=settings.TRN_BATCH_SIZE,\n",
    "                 verbose=1,\n",
    "                 shuffle=True,\n",
    "                 validation_data=(val_imgs, val_grndtr_ext_conv),\n",
    "                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(hist,\n",
    "                      settings.TRN_NUM_EPOCH,\n",
    "                      show=False,\n",
    "                      save_path=settings.OUTPUT_PATH + unet.title,\n",
    "                      time_stamp=True,\n",
    "                      metric=\"dice_coef\")\n",
    "\n",
    "print(\"\\n--- Training complete\")\n",
    "\n",
    "print(\"Elapsed training time: {} min\".format(int((time.time() - start_time))/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform pipeline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Pipeline test\")\n",
    "# For pipeline testing only, predict on one training image\n",
    "predictions = model.predict(train_imgs[[0]], batch_size=settings.TRN_BATCH_SIZE, verbose=2)\n",
    "\n",
    "# predictions = predictions\n",
    "# predictions = convert_pred_to_img_flatten(predictions, settings.TRN_PRED_THRESHOLD)\n",
    "predictions = convert_pred_to_img(predictions, settings, settings.TRN_PRED_THRESHOLD)\n",
    "\n",
    "show_image(np.squeeze(train_imgs[0]), 'PRED TRAIN org image')\n",
    "show_image(np.squeeze(train_grndtr[0]), 'PRED TRAIN org ground truth')\n",
    "show_image(np.squeeze(predictions[0]), 'PRED TRAIN predicted mask')\n",
    "\n",
    "print(\"  original {} dtype {}\".format(np.max(train_imgs[0]), train_imgs[0].dtype))\n",
    "print(\"  gr truth {} dtype {}\".format(np.max(train_grndtr[0]), train_grndtr[0].dtype))\n",
    "print(\"prediction {} dtype {}\".format(np.max(predictions[0]), predictions[0].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
