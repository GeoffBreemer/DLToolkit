{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DECiSION\n",
    "Train a U-Net model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set seeds and import packages\n",
    "Settings the seeds first is meant to achieve reproducibility, though this goal is not achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoff/anaconda3/envs/ML3-DL-OPENCV/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Set Python, NumPy and TensorFlow seeds\n",
    "RANDOM_STATE = 42\n",
    "from numpy.random import seed\n",
    "seed(RANDOM_STATE)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(RANDOM_STATE)\n",
    "\n",
    "import random\n",
    "random.seed = RANDOM_STATE\n",
    "\n",
    "# Model and training settings\n",
    "import DECiSION_settings as settings\n",
    "\n",
    "# Toolkit imports\n",
    "from dltoolkit.utils.generic import model_architecture_to_file, model_summary_to_file, list_images\n",
    "from dltoolkit.nn.segment import UNet_NN\n",
    "from dltoolkit.utils.visual import plot_training_history, plot_roc_curve, plot_precision_recall_curve,\\\n",
    "    print_confusion_matrix, print_classification_report\n",
    "from dltoolkit.iomisc import HDF5Generator_Segment\n",
    "\n",
    "from thesis_common import convert_img_to_pred, convert_pred_to_img, create_hdf5_db,\\\n",
    "    show_image, read_images, read_groundtruths, print_training_info\n",
    "from thesis_metric_loss import dice_coef, weighted_pixelwise_crossentropy_loss\n",
    "\n",
    "# Keras imports\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Other imports\n",
    "import numpy as np\n",
    "import os, cv2, time, progressbar\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change how TensorFlow allocates GPU memory\n",
    "This has no effect on non-GPU machines. Setting `gpu_options.allow_growth` to `True` means TensorFlow will allocate GPU memory as needed rather than using all memory from the start. This enables monitoring of actual memory usage and determining how close the notebook gets to running out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a percentage of the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    " \n",
    "# Create a session with the above options specified\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine how to train\n",
    "The variables below determine how the model will be trained:\n",
    "\n",
    "- `USE_GENERATORS`: when set to `True` the training process will use data generators, which is typically what will be required given the size of the models being trained and the size of the images. Set to `False` to (try) to load all data into memory.\n",
    "- `USE_VALIDATION_SET`: set to `True` to use a validation set during training, which will be used most of the tie. set to `False` to not use a validation set, which is used during pipeline validation.\n",
    "- `USE_KFOLD_CV`: set to `True` to use k-fold cross validation during training, `False` otherwise. k-Fold cross validation requires all data to be loaded into memory and does not use a validation set, so the `USE_GENERATORS` and `USE_VALIDATION_SET` variables are both set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_KFOLD_CV = False\n",
    "\n",
    "USE_GENERATORS = True\n",
    "USE_VALIDATION_SET = True\n",
    "\n",
    "if USE_KFOLD_CV:\n",
    "    # For now k-Fold CV only works with all data in memory\n",
    "    USE_GENERATORS = False\n",
    "    USE_VALIDATION_SET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert individual images set to HDF5 data sets\n",
    "This function converts the individual JPG files to HDF5 data sets. It creates up to four HDF5 files depending on whether a portion of the files is set aside to create a validation set using `settings.TRN_TRAIN_VAL_SPLIT`.\n",
    "\n",
    "This conversion only has to be performed once rather than prior to every training run. However, it takes very little time to run. Note: if any changes are made to image pre-processing applied to MRI images and/or their ground truths, the conversion MUST be executed prior to any training. Otherwise training will occur withoug the pre-processing changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def perform_hdf5_conversion(settings):\n",
    "    \"\"\"Convert the individual .jpg files (images and ground truths) to four .hdf5 files:\n",
    "    - Two with the training set (train_images.h5 and train_groundtruths.h5)\n",
    "    - Two with the validation set (val_images.h5 and val_groundtruths.h5)\n",
    "    \n",
    "    If TRN_TRAIN_VAL_SPLIT is set to zero the validation set data sets are NOT generated.\n",
    "    \"\"\"\n",
    "    # Prepare the path to the training images and ground truths\n",
    "    img_exts = \".jpg\"\n",
    "    img_path = os.path.join(settings.TRAINING_PATH, settings.FLDR_IMAGES)\n",
    "    msk_path = os.path.join(settings.TRAINING_PATH, settings.FLDR_GROUND_TRUTH)\n",
    "\n",
    "    # Create a list of paths to the individual patient folders\n",
    "    patient_fld_imgs = sorted([os.path.join(img_path, e.name) for e in os.scandir(img_path) if e.is_dir()])\n",
    "    patient_fld_masks = sorted([os.path.join(msk_path, e.name) for e in os.scandir(msk_path) if e.is_dir()])\n",
    "\n",
    "    # Obtain a list of paths to the training images and ground truths for each patient\n",
    "    img_list = []\n",
    "    msk_list = []\n",
    "    for patient_ix, (p_fld_imgs, p_fld_masks) in enumerate(zip(patient_fld_imgs, patient_fld_masks)):\n",
    "        img_list.extend(sorted(list(list_images(basePath=p_fld_imgs,\n",
    "                                                validExts=img_exts)))\n",
    "                        [settings.SLICE_START:settings.SLICE_END])\n",
    "        msk_list.extend(sorted(list(list_images(basePath=p_fld_masks,\n",
    "                                                validExts=img_exts)))\n",
    "                        [settings.SLICE_START:settings.SLICE_END])\n",
    "\n",
    "    assert(len(img_list) == len(msk_list))\n",
    "\n",
    "    # Split the training set into a training and validation set. Consecutive slices no longer\n",
    "    # belong to the same patient\n",
    "    train_img, val_img, train_msk, val_msk = train_test_split(img_list, msk_list,\n",
    "                                                              test_size=settings.TRN_TRAIN_VAL_SPLIT,\n",
    "                                                              random_state=settings.RANDOM_STATE,\n",
    "                                                              shuffle=True)\n",
    "    \n",
    "    # Create the HDF5 data sets\n",
    "    output_paths = []\n",
    "\n",
    "    # Training images\n",
    "    output_paths.append(create_hdf5_db(train_img, \"train\", img_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings))\n",
    "\n",
    "    # Training ground truths\n",
    "    output_paths.append(create_hdf5_db(train_msk, \"train\", msk_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings,\n",
    "                                       is_mask=True))\n",
    "\n",
    "    # Validation images\n",
    "    output_paths.append(create_hdf5_db(val_img, \"val\", img_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings))\n",
    "\n",
    "    # Validation ground truths\n",
    "    output_paths.append(create_hdf5_db(val_msk, \"val\", msk_path,\n",
    "                                       (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                       key=settings.HDF5_KEY, ext=settings.HDF5_EXT, settings=settings,\n",
    "                                       is_mask=True))\n",
    "\n",
    "    return output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating HDF5 database 100% |###################################| Time: 0:00:00\n",
      "Creating HDF5 database 100% |###################################| Time: 0:00:00\n",
      "Creating HDF5 database 100% |###################################| Time: 0:00:00\n",
      "Creating HDF5 database 100% |###################################| Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Converting images to HDF5, full paths:\n",
      "\n",
      "../data/MSC8002/training/train_images.h5\n",
      "../data/MSC8002/training/train_groundtruths.h5\n",
      "../data/MSC8002/training/val_images.h5\n",
      "../data/MSC8002/training/val_groundtruths.h5\n",
      "\n",
      "Created a 0.1 training/validation set\n"
     ]
    }
   ],
   "source": [
    "if settings.IS_DEVELOPMENT:\n",
    "    print(\"\\n--- Converting images to HDF5, full paths:\\n\")\n",
    "    hdf5_paths = perform_hdf5_conversion(settings)\n",
    "    \n",
    "    if settings.TRN_TRAIN_VAL_SPLIT == 0:\n",
    "        print(\"\\nValidation set NOT created.\")\n",
    "    else:\n",
    "        print(\"\\nCreated a {} training/validation set\".format(settings.TRN_TRAIN_VAL_SPLIT))\n",
    "else:\n",
    "    # During development avoid performing HDF5 conversion for every run\n",
    "    hdf5_paths = [\"../data/MSC8002/training/train_images.h5\",\n",
    "                  \"../data/MSC8002/training/train_groundtruths.h5\",\n",
    "                  \"../data/MSC8002/training/val_images.h5\",\n",
    "                  \"../data/MSC8002/training/val_groundtruths.h5\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the class distribution\n",
    "Assigning a higher weight to the positive class (i.e. blood vessels) means the model will pay `more attention` to that class. This is useful in the current scenario because the number of background (i.e. non-blood vessel) pixels far exceed the number of blood vessel pixels. Without setting a different class weight for the blood vessel class the model would simply assign the background class to all pixels to achieve a low loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [1.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "class_weights = [settings.CLASS_WEIGHT_BACKGROUND, settings.CLASS_WEIGHT_BLOODVESSEL]\n",
    "print(\"Class distribution: {}\".format(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the U-Net model\n",
    "Instantiate the U-Net model. Use different versions of the `build_model_XXX()` function to try different variations. Warning: Changing the model will change the name of the file the trained model will be saved to. Make sure to update the `DECiSION_test` notebook accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unet = UNet_NN(img_height=settings.IMG_HEIGHT,\n",
    "               img_width=settings.IMG_WIDTH,\n",
    "               img_channels=settings.IMG_CHANNELS,\n",
    "               num_classes=settings.NUM_CLASSES,\n",
    "               dropout_rate=settings.TRN_DROPOUT_RATE)\n",
    "model = unet.build_model_BRAIN_3layer(use_bn=True, use_dropout=False)\n",
    "# model = unet.build_model_BRAIN_4layer(use_bn=True, use_dropout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create paths\n",
    "This cell just creates a few paths used later to save training output (e.g. the model architecture, training results and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare some path strings\n",
    "model_path = os.path.join(settings.MODEL_PATH, \"DECiSION_\" + unet.title + \"_ep{}.model\".format(settings.TRN_NUM_EPOCH))\n",
    "summ_path = os.path.join(settings.OUTPUT_PATH, \"DECiSION_\" + unet.title + \"_model_summary.txt\")\n",
    "csv_path = os.path.join(settings.OUTPUT_PATH, \"DECiSION_\" + unet.title + \"_training_ep{}_bs{}.csv\".format(settings.TRN_NUM_EPOCH,\n",
    "                                                                                            settings.TRN_BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/print model architecture information\n",
    "Save the U-Net model's architecture to a file and print it in the cell below. Also saves a diagram of the architecture to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model_summary_to_file(model, summ_path)\n",
    "model_architecture_to_file(unet.model, settings.OUTPUT_PATH + \"DECiSION_\" + unet.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model\n",
    "Set the loss function, optimiser and metric and compile the model, which is now ready for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the optimiser, loss function and metrics\n",
    "opt = Adam()\n",
    "# opt = Adadelta()\n",
    "metrics = [dice_coef]\n",
    "loss = weighted_pixelwise_crossentropy_loss(class_weights)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The two cells below load the training data. Depending on the value of `USE_GENERATORS` data is either loaded using a generator or it is loaded into memory. The latter option is useful during development, the latter option is almost always required when training with a large(r) number of training images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Use generators\n",
    "Nothing is actually loaded at this point. Only the generators are prepared for use with `fit_generator()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare generators, only when NOT using cross validation\n",
    "if USE_GENERATORS:\n",
    "    print(\"Using data generators\")\n",
    "    # Training set generator using optional on-the-fly data augmentation\n",
    "    rdr_train = HDF5Generator_Segment(hdf5_paths[0], hdf5_paths[1],\n",
    "                                      batch_size=settings.TRN_BATCH_SIZE,\n",
    "                                      num_classes=settings.NUM_CLASSES,\n",
    "                                      converter=convert_img_to_pred, \n",
    "                                      feat_key=settings.HDF5_KEY)\n",
    "    gen_train = rdr_train.generator(num_epochs=settings.TRN_NUM_EPOCH)\n",
    "\n",
    "    # Validation set generator (never uses data augmentation)\n",
    "    rdr_val = HDF5Generator_Segment(hdf5_paths[2], hdf5_paths[3],\n",
    "                                    batch_size=settings.TRN_BATCH_SIZE,\n",
    "                                    num_classes=settings.NUM_CLASSES,\n",
    "                                    converter=convert_img_to_pred, \n",
    "                                    feat_key=settings.HDF5_KEY)\n",
    "    gen_val = rdr_val.generator(num_epochs=settings.TRN_NUM_EPOCH)\n",
    "\n",
    "    print(\"  Number of training samples: {}\".format(rdr_train.num_images()))\n",
    "    print(\"Number of validation samples: {}\".format(rdr_val.num_images()))\n",
    "\n",
    "    print(\" steps_per_epoch: {}\".format(rdr_train.num_images()/settings.TRN_BATCH_SIZE))\n",
    "    print(\"validation_steps: {}\".format(rdr_val.num_images()/settings.TRN_BATCH_SIZE))\n",
    "else:\n",
    "    print(\"Not creating generators.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Load all data into memory\n",
    "All data is loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_GENERATORS:\n",
    "    print(\"Loading all data into memory\")\n",
    "\n",
    "    train_imgs = read_images(hdf5_paths[0], settings.HDF5_KEY)\n",
    "    train_grndtr = read_groundtruths(hdf5_paths[1], settings.HDF5_KEY)\n",
    "    train_grndtr_ext_conv = convert_img_to_pred(train_grndtr, settings.NUM_CLASSES, settings.VERBOSE)  # softmax: 4D\n",
    "    print(\"  Number of training samples: {}\\n\".format(len(train_imgs)))\n",
    "\n",
    "    # Read the validation set (only when NOT using cross-validation)\n",
    "    if not USE_KFOLD_CV:\n",
    "        val_imgs = read_images(hdf5_paths[2], settings.HDF5_KEY)\n",
    "        val_grndtr = read_groundtruths(hdf5_paths[3], settings.HDF5_KEY)\n",
    "        val_grndtr_ext_conv = convert_img_to_pred(val_grndtr, settings.NUM_CLASSES, settings.VERBOSE)  # softmax: 4D\n",
    "        print(\"Number of validation samples: {}\\n\".format(len(val_imgs)))\n",
    "    else:\n",
    "        print(\"Using cross validation, not loading a validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model using generators\n",
    "The two cells below perform actual training using generators. The first one uses a validation set, the second one does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train WITH a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if USE_GENERATORS and USE_VALIDATION_SET:\n",
    "    # Prepare callbacks\n",
    "    callbacks = [ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "                 EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0,\n",
    "                               patience=settings.TRN_EARLY_PATIENCE,\n",
    "                               verbose=0,\n",
    "                               mode=\"auto\"),\n",
    "                 CSVLogger(csv_path, append=False),\n",
    "                 ]\n",
    "\n",
    "    print(\"Training with a validation set, using generators.\")\n",
    "    print_training_info(unet, model_path, rdr_train.img_shape, settings, class_weights, opt, loss)\n",
    "    print(\"Training start:\\n\")\n",
    "\n",
    "    # Fit the model using generators and a validation set\n",
    "    start_time = time.time()\n",
    "    hist = model.fit_generator(gen_train,\n",
    "#                      epochs=settings.TRN_NUM_EPOCH,\n",
    "                     epochs=2,\n",
    "                     steps_per_epoch=rdr_train.num_images()/settings.TRN_BATCH_SIZE,\n",
    "                     verbose=2,\n",
    "                     validation_data=gen_val,\n",
    "                     validation_steps=rdr_val.num_images()/settings.TRN_BATCH_SIZE,\n",
    "                     shuffle=True,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "    print(\"\\n\\nElapsed training time: {} min\".format(int((time.time() - start_time))/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train WITHOUT a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GENERATORS and not USE_VALIDATION_SET:\n",
    "    # Prepare callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, monitor=\"loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='loss', min_delta=0, patience=settings.TRN_EARLY_PATIENCE, verbose=0, mode=\"auto\"),\n",
    "        CSVLogger(csv_path, append=False),\n",
    "        ]\n",
    "\n",
    "    print(\"Training without a validation set, using generators.\")\n",
    "    print_training_info(unet, model_path, rdr_train.img_shape, settings, class_weights, opt, loss)\n",
    "    print(\"Training start:\\n\")\n",
    "\n",
    "    # Fit the model using a training set only\n",
    "    start_time = time.time()\n",
    "    hist = model.fit_generator(gen_train,\n",
    "                     epochs=settings.TRN_NUM_EPOCH,\n",
    "    #                  epochs=3,\n",
    "                     steps_per_epoch=rdr_train.num_images()/settings.TRN_BATCH_SIZE,\n",
    "                     verbose=2,\n",
    "                     shuffle=True,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "    print(\"\\n\\nElapsed training time: {} min\".format(int((time.time() - start_time))/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with all data loaded in memory\n",
    "The two cells below perform actual training using data loaded into memory. The first one uses a validation set, the second one does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train WITH a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_GENERATORS and USE_VALIDATION_SET:\n",
    "    print(\"Training with a validation set, using generators.\")\n",
    "    print_training_info(unet, model_path, train_imgs.shape, settings, class_weights, opt, loss)\n",
    "    print(\"Training start:\\n\")\n",
    "\n",
    "    # Prepare callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='val_loss', min_delta=0, patience=settings.TRN_EARLY_PATIENCE, verbose=0, mode=\"auto\"),\n",
    "        CSVLogger(csv_path, append=False),\n",
    "        ]\n",
    "\n",
    "    # Fit the model using a training set only\n",
    "    start_time = time.time()\n",
    "    hist = model.fit(train_imgs, train_grndtr_ext_conv,\n",
    "                     epochs=settings.TRN_NUM_EPOCH,\n",
    "                     batch_size=settings.TRN_BATCH_SIZE,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(val_imgs, val_grndtr_ext_conv),\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "    print(\"\\n\\nElapsed training time: {} min\".format(int((time.time() - start_time))/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train WITHOUT a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_GENERATORS and not USE_VALIDATION_SET:\n",
    "    print(\"Training without a validation set, all data in memory.\")\n",
    "    print_training_info(unet, model_path, train_imgs.shape, settings, class_weights, opt, loss)\n",
    "    print(\"Training start:\\n\")\n",
    "\n",
    "    # Prepare callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, monitor=\"loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='loss', min_delta=0, patience=settings.TRN_EARLY_PATIENCE, verbose=0, mode=\"auto\"),\n",
    "        CSVLogger(csv_path, append=False),\n",
    "        ]\n",
    "\n",
    "    # Fit the model using a training set only\n",
    "    start_time = time.time()\n",
    "    hist = model.fit(train_imgs, train_grndtr_ext_conv,\n",
    "                     epochs=settings.TRN_NUM_EPOCH,\n",
    "                     batch_size=settings.TRN_BATCH_SIZE,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "    print(\"\\n\\nElapsed training time: {} min\".format(int((time.time() - start_time))/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "\n",
    "https://github.com/keras-team/keras/issues/4530\n",
    "\n",
    "https://stackoverflow.com/questions/40854232/keras-scikit-learn-using-fit-generator-with-cross-validation/40866543#40866543\n",
    "\n",
    "https://stackoverflow.com/questions/41214527/k-fold-cross-validation-using-keras\n",
    "\n",
    "https://www.kaggle.com/stefanie04736/simple-keras-model-with-k-fold-cross-validation\n",
    "\n",
    "NICE: https://www.kaggle.com/zfturbo/fishy-keras-lb-1-25267/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if USE_KFOLD_CV:\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    print(\"Training using cross validation\")\n",
    "    print_training_info(unet, model_path, train_imgs.shape, settings, class_weights, opt, loss)\n",
    "    print(\"Training start:\\n\")\n",
    "\n",
    "    # Set the optimiser, loss function and metrics\n",
    "    opt = Adam()\n",
    "    metrics = [dice_coef]\n",
    "    loss = weighted_pixelwise_crossentropy_loss(class_weights)\n",
    "\n",
    "    # Create the folds\n",
    "    kfold = KFold(n_splits=settings.TRN_NUM_KFOLD_SPLITS, shuffle=True, random_state=settings.RANDOM_STATE)\n",
    "    cvscores = []\n",
    "    cvlosses = []\n",
    "    fold_id = 1\n",
    "    for train_idx, test_idx in kfold.split(train_imgs, train_grndtr_ext_conv):\n",
    "        print(\"\\n-----> Fold {} of {} <-----\".format(fold_id, settings.TRN_NUM_KFOLD_SPLITS))\n",
    "        print(\"Training: {} slices, test: {} slices\".format(len(train_idx), len(test_idx)))\n",
    "        \n",
    "        # Create and compile the model before each fold (to reset the weights)\n",
    "        model = unet.build_model_softmax()\n",
    "        model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "\n",
    "        # Include the number of the fold in the file name\n",
    "        kfold_path = os.path.join(settings.MODEL_PATH, \"DECiSION_\" + unet.title + \"_ep{}_kfold{}.model\".format(settings.TRN_NUM_EPOCH, fold_id))\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(kfold_path, monitor=\"loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "            EarlyStopping(monitor='loss', min_delta=0, patience=settings.TRN_EARLY_PATIENCE, verbose=0, mode=\"auto\"),\n",
    "            CSVLogger(csv_path, append=False),\n",
    "        ]\n",
    "\n",
    "        hist = model.fit(train_imgs[train_idx], train_grndtr_ext_conv[train_idx],\n",
    "                         epochs=settings.TRN_NUM_EPOCH,\n",
    "                         batch_size=settings.TRN_BATCH_SIZE,\n",
    "                         verbose=2,\n",
    "                         shuffle=True,\n",
    "                         callbacks=callbacks)\n",
    "\n",
    "        scores = model.evaluate(train_imgs[test_idx], train_grndtr_ext_conv[test_idx], verbose=2)\n",
    "        print(\"\\n-----> Fold {}: {}: {:.2f}%% - {}: {:.2f}\\n\".format(fold_id,\n",
    "                                                          model.metrics_names[1],\n",
    "                                                          scores[1]*100,\n",
    "                                                          model.metrics_names[0],\n",
    "                                                          scores[0]))\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        cvlosses.append(scores[0])\n",
    "\n",
    "        fold_id += 1\n",
    "\n",
    "    print(\"Results\")\n",
    "    print(\"------------------\")\n",
    "    for i in range(NUM_SPLITS):\n",
    "        print(\"Fold {}: {}: {:.2f}% - {}: {:.2f}\\n\".format(i,\n",
    "                                                          model.metrics_names[1],\n",
    "                                                          cvscores[i],\n",
    "                                                          model.metrics_names[0],\n",
    "                                                          cvlosses[i]))\n",
    "    print(\"------------------\")\n",
    "\n",
    "    print(\"\\nEstimated test performance: mean and std dev\")\n",
    "    print(\"------------------\")\n",
    "    print(\"\\n{}: {:.2f} (+/- {:.2f})\".format(model.metrics_names[0], np.mean(cvlosses), np.std(cvlosses)))\n",
    "    print(\"{}: {:.2f}% (+/- {:.2f}%)\".format(model.metrics_names[1], np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "    print(\"\\nFold Id with the highest DICE: {}\".format(np.argmax(cvscores)+1))\n",
    "    print(\" Fold Id with the lowest loss: {}\".format(np.argmin(cvscores)+1))\n",
    "    \n",
    "    print(\"\\nFitting model using all training data\")\n",
    "    print(\"------------------\")\n",
    "    # Prepare callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, monitor=\"loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='loss', min_delta=0, patience=settings.TRN_EARLY_PATIENCE, verbose=0, mode=\"auto\"),\n",
    "        CSVLogger(csv_path, append=False),\n",
    "        ]\n",
    "\n",
    "    model = unet.build_model_softmax()\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "\n",
    "    # Fit the model using a training set only\n",
    "    start_time = time.time()\n",
    "    hist = model.fit(train_imgs, train_grndtr_ext_conv,\n",
    "                     epochs=settings.TRN_NUM_EPOCH,\n",
    "                     batch_size=settings.TRN_BATCH_SIZE,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "    print(\"\\n\\nElapsed training time: {} min\".format(int((time.time() - start_time))/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot/save the training results\n",
    "Show a plot of the training history and save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not USE_KFOLD_CV:\n",
    "    plot_training_history(hist,\n",
    "                          show=True,\n",
    "                          save_path=settings.OUTPUT_PATH + unet.title,\n",
    "                          time_stamp=True,\n",
    "                          metric=\"dice_coef\")\n",
    "else:\n",
    "    print(\"Using cross-validation, no training history saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform pipeline test\n",
    "Use the trained model on one sample in the training data set. This is just to perform pipeline testing during development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read training images and ground truths\n",
    "train_imgs = read_images(hdf5_paths[0], settings.HDF5_KEY)\n",
    "train_grndtr = read_groundtruths(hdf5_paths[1], settings.HDF5_KEY)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(train_imgs, batch_size=settings.TRN_BATCH_SIZE, verbose=2)\n",
    "print(\"Predictions shape: {}\".format(predictions.shape))\n",
    "\n",
    "# Convert predictions to images\n",
    "predictions_imgs = convert_pred_to_img(predictions,\n",
    "                                       threshold=settings.TRN_PRED_THRESHOLD,\n",
    "                                       verbose=settings.VERBOSE)\n",
    "\n",
    "# Show a single image, ground truth and segmentation map\n",
    "show_image(np.squeeze(predictions_imgs[0]), 'Segmentation map')\n",
    "show_image(np.squeeze(train_grndtr[0]), 'Ground truth')\n",
    "show_image(np.squeeze(train_imgs[0]), 'Original image')\n",
    "\n",
    "print(\"   seg map {} dtype {}\".format(np.max(predictions_imgs[0]), predictions_imgs[0].dtype))\n",
    "print(\"  gr truth {} dtype {}\".format(np.max(train_grndtr[0]), train_grndtr[0].dtype))\n",
    "print(\"  original {} dtype {}\".format(np.max(train_imgs[0]), train_imgs[0].dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Training complete\n",
    "The trained model is now ready to be applied to test MRI images using `DECiSION_test.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
