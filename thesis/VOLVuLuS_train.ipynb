{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VOLVuLuS incl. data augmentation\n",
    "Train a 3D U-net model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set seeds and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoff/anaconda3/envs/ML3-DL-OPENCV/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "from numpy.random import seed\n",
    "seed(RANDOM_STATE)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(RANDOM_STATE)\n",
    "\n",
    "import random\n",
    "random.seed = RANDOM_STATE\n",
    "\n",
    "import VOLVuLuS_settings as settings\n",
    "\n",
    "from dltoolkit.utils.generic import model_architecture_to_file, model_summary_to_file, list_images\n",
    "from dltoolkit.nn.segment import UNet_3D_NN\n",
    "from dltoolkit.utils.visual import plot_training_history, plot_roc_curve, plot_precision_recall_curve,\\\n",
    "    print_confusion_matrix, print_classification_report\n",
    "from dltoolkit.iomisc import HDF5Generator_Segment\n",
    "\n",
    "from thesis_common import convert_img_to_pred_3D, convert_pred_to_img_3D, create_hdf5_db_3D,\\\n",
    "    show_image, read_images, read_groundtruths, print_training_info\n",
    "from thesis_metric_loss import dice_coef, weighted_pixelwise_crossentropy_loss\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os, cv2, time, progressbar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change how TensorFlow allocates GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a percentage of the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    " \n",
    "# Create a session with the above options specified\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert training set to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hdf5_conversion_3D(settings):\n",
    "    \"\"\"Convert the training and test images, ground truths and masks to HDF5 format. The assumption is that images\n",
    "    are all placed in the same folder, regardless of the patient.\n",
    "    \"\"\"\n",
    "    output_paths = []\n",
    "\n",
    "    print(\"training images\")\n",
    "    # Convert training images in each sub folder to a single HDF5 file\n",
    "    output_paths.append(create_hdf5_db_3D(os.path.join(settings.TRAINING_PATH, settings.FLDR_IMAGES),\n",
    "                                        (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                        img_exts=\".jpg\", key=settings.HDF5_KEY, ext=settings.HDF5_EXT,\n",
    "                                        settings=settings))\n",
    "\n",
    "    print(\"training ground truths\")\n",
    "    # Training ground truths\n",
    "    output_paths.append(create_hdf5_db_3D(os.path.join(settings.TRAINING_PATH, settings.FLDR_GROUND_TRUTH),\n",
    "                                        (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                        img_exts=\".jpg\", key=settings.HDF5_KEY, ext=settings.HDF5_EXT,\n",
    "                                        settings=settings, is_mask=True))\n",
    "\n",
    "    # Do the same for the test images\n",
    "    print(\"test images\")\n",
    "    output_paths.append(create_hdf5_db_3D(os.path.join(settings.TEST_PATH, settings.FLDR_IMAGES),\n",
    "                                        (settings.IMG_HEIGHT, settings.IMG_WIDTH, settings.IMG_CHANNELS),\n",
    "                                        img_exts=\".jpg\", key=settings.HDF5_KEY, ext=settings.HDF5_EXT,\n",
    "                                        settings=settings))\n",
    "\n",
    "    return output_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable/disable cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_KFOLD_CV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating HDF5 database 100% |###################################| Time: 0:00:00\n",
      "Creating HDF5 database 100% |###################################| Time: 0:00:00\n",
      "Creating HDF5 database 100% |###################################| Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Converting images to HDF5\n",
      "training images\n",
      "training ground truths\n",
      "test images\n",
      "Not creating a validation set\n"
     ]
    }
   ],
   "source": [
    "# Convert image files to HDF5\n",
    "if settings.IS_DEVELOPMENT:\n",
    "    print(\"\\n--- Converting images to HDF5\")\n",
    "    hdf5_paths = perform_hdf5_conversion_3D(settings)\n",
    "    \n",
    "    if settings.TRN_TRAIN_VAL_SPLIT == 0:\n",
    "        print(\"Not creating a validation set\")\n",
    "    else:\n",
    "        print(\"Creating a {} training/validation set\".format(settings.TRN_TRAIN_VAL_SPLIT))\n",
    "else:\n",
    "    # During development avoid performing HDF5 conversion for every run\n",
    "        hdf5_paths = [\"../data/MSC8002/training_3d/images.h5\",\n",
    "                      \"../data/MSC8002/training_3d/groundtruths.h5\",\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print class distribution\n",
    "class_weights = [settings.CLASS_WEIGHT_BACKGROUND, settings.CLASS_WEIGHT_BLOODVESSEL]\n",
    "print(\"Class distribution: {}\".format(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the 3D U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet_3D_NN(img_height=settings.IMG_HEIGHT,\n",
    "                  img_width=settings.IMG_WIDTH,\n",
    "                  num_slices=settings.SLICE_END - settings.SLICE_START,\n",
    "                  img_channels=settings.IMG_CHANNELS,\n",
    "                  num_classes=settings.NUM_CLASSES)\n",
    "# model = unet.build_model()\n",
    "model = unet.build_model_3lyr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare some path strings\n",
    "model_path = os.path.join(settings.MODEL_PATH, \"VOLVuLuS_\" + unet.title + \"_ep{}.model\".format(settings.TRN_NUM_EPOCH))\n",
    "summ_path = os.path.join(settings.OUTPUT_PATH, \"VOLVuLuS_\" + unet.title + \"_model_summary.txt\")\n",
    "csv_path = os.path.join(settings.OUTPUT_PATH, \"VOLVuLuS_\" + unet.title + \"_training_ep{}_bs{}.csv\".format(settings.TRN_NUM_EPOCH,\n",
    "                                                                                            settings.TRN_BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/print model architecture information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model_summary_to_file(model, summ_path)\n",
    "model_architecture_to_file(unet.model, settings.OUTPUT_PATH + \"VOLVuLuS_\" + unet.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimiser, loss function and metrics\n",
    "opt = Adam()\n",
    "metrics = [dice_coef]\n",
    "loss = weighted_pixelwise_crossentropy_loss(class_weights)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Use generators"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Prepare generators, only when NOT using cross validation\n",
    "if USE_KFOLD_CV is False:\n",
    "    # Training set generator using data augmentation\n",
    "    rdr_train = HDF5Generator_Segment(hdf5_paths[0], hdf5_paths[1],\n",
    "                                      batch_size=settings.TRN_BATCH_SIZE,\n",
    "                                      num_classes=settings.NUM_CLASSES,\n",
    "                                      converter=convert_img_to_pred, \n",
    "    #                                   data_gen_args=data_gen_args,\n",
    "                                      feat_key=settings.HDF5_KEY)\n",
    "    gen_train = rdr_train.generator(num_epochs=settings.TRN_NUM_EPOCH)\n",
    "\n",
    "    # Validation set generator (does NOT use data augmentation)\n",
    "    rdr_val = HDF5Generator_Segment(hdf5_paths[2], hdf5_paths[3],\n",
    "                                    batch_size=settings.TRN_BATCH_SIZE,\n",
    "                                    num_classes=settings.NUM_CLASSES,\n",
    "                                    converter=convert_img_to_pred, \n",
    "                                    feat_key=settings.HDF5_KEY)\n",
    "    gen_val = rdr_val.generator(num_epochs=settings.TRN_NUM_EPOCH)\n",
    "\n",
    "    print(\" num trn samples: {}\".format(rdr_train.num_images()))\n",
    "    print(\" num val samples: {}\".format(rdr_val.num_images()))\n",
    "\n",
    "    print(\" steps_per_epoch: {}\".format(rdr_train.num_images()/settings.TRN_BATCH_SIZE))\n",
    "    print(\"validation_steps: {}\".format(rdr_val.num_images()/settings.TRN_BATCH_SIZE))\n",
    "else:\n",
    "    print(\"Using cross validation, not creating generators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Load all data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = read_images(hdf5_paths[0], settings.HDF5_KEY, is_3D=True)\n",
    "train_grndtr = read_groundtruths(hdf5_paths[1], settings.HDF5_KEY, is_3D=True)\n",
    "train_grndtr_ext_conv = convert_img_to_pred_3D(train_grndtr, settings.NUM_CLASSES, settings.VERBOSE)\n",
    "\n",
    "print(\"Number of samples: {}\".format(len(train_imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train WITH a validation set - ALL IN MEMORY"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if not USE_KFOLD_CV:\n",
    "    print(\"Training with a training/validation split.\")\n",
    "    print_training_info(unet, model_path, train_imgs.shape, val_imgs.shape, settings, class_weights, 1, opt, loss)\n",
    "    print(\"Training start:\\n\")\n",
    "\n",
    "    # Prepare callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='val_loss', min_delta=0, patience=settings.TRN_EARLY_PATIENCE, verbose=0, mode=\"auto\"),\n",
    "        CSVLogger(csv_path, append=False),\n",
    "        ]\n",
    "\n",
    "    # Fit the model using a training set only\n",
    "    start_time = time.time()\n",
    "    hist = model.fit(train_imgs, train_grndtr_ext_conv,\n",
    "                     epochs=settings.TRN_NUM_EPOCH,\n",
    "#                      epochs=2,\n",
    "                     batch_size=settings.TRN_BATCH_SIZE,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(val_imgs, val_grndtr_ext_conv),\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "    print(\"\\n\\nElapsed training time: {:.2f} min\".format(int((time.time() - start_time))/60))\n",
    "else:\n",
    "    print(\"Cross-validation selected, not performing one-off training with a validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train WITHOUT a validation set - ALL IN MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_KFOLD_CV:\n",
    "    print(\"Training with just a training set, no validation set used.\")\n",
    "    print_training_info(unet, model_path, train_imgs.shape, None, settings, class_weights, 1, opt, loss)\n",
    "    print(\"Training start:\\n\")\n",
    "    \n",
    "    # Prepare callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, monitor=\"loss\", mode=\"min\", save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='loss', min_delta=0, patience=settings.TRN_EARLY_PATIENCE, verbose=0, mode=\"auto\"),\n",
    "        CSVLogger(csv_path, append=False),\n",
    "        ]\n",
    "\n",
    "    # Fit the model using a training set only\n",
    "    start_time = time.time()\n",
    "    hist = model.fit(train_imgs, train_grndtr_ext_conv,\n",
    "                     epochs=settings.TRN_NUM_EPOCH,\n",
    "                     batch_size=settings.TRN_BATCH_SIZE,\n",
    "                     verbose=2,\n",
    "                     shuffle=True,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "    print(\"\\n\\nElapsed training time: {:.2f} min\".format(int((time.time() - start_time))/60))\n",
    "else:\n",
    "    print(\"Cross-validation selected, not performing one-off training with just a training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_KFOLD_CV:\n",
    "    plot_training_history(hist,\n",
    "                          show=False,\n",
    "                          save_path=settings.OUTPUT_PATH + unet.title,\n",
    "                          time_stamp=True,\n",
    "                          metric=\"dice_coef\")\n",
    "else:\n",
    "    print(\"Using cross-validation, no training history saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform pipeline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and ground truths\n",
    "train_imgs = read_images(hdf5_paths[0], settings.HDF5_KEY, is_3D=True)\n",
    "train_grndtr = read_groundtruths(hdf5_paths[1], settings.HDF5_KEY, is_3D=True)\n",
    "\n",
    "# For pipeline testing only\n",
    "predictions = model.predict(train_imgs, batch_size=settings.TRN_BATCH_SIZE, verbose=2)\n",
    "\n",
    "# Transpose images and ground truths to the correct oder\n",
    "train_imgs = np.transpose(train_imgs, axes=(0, 3, 1, 2, 4))\n",
    "train_grndtr = np.transpose(train_grndtr, axes=(0, 3, 1, 2, 4))\n",
    "\n",
    "# predictions = predictions\n",
    "predictions_imgs = convert_pred_to_img_3D(predictions,\n",
    "                                       threshold=settings.TRN_PRED_THRESHOLD,\n",
    "                                       verbose=settings.VERBOSE)\n",
    "\n",
    "show_image(np.squeeze(train_imgs[0, 0]), 'PRED TRAIN org image')\n",
    "show_image(np.squeeze(train_grndtr[0, 0]), 'PRED TRAIN org ground truth')\n",
    "show_image(np.squeeze(predictions_imgs[0, 0]), 'PRED TRAIN predicted mask')\n",
    "\n",
    "print(\"  original {} dtype {}\".format(np.max(train_imgs[0,0]), train_imgs[0,0].dtype))\n",
    "print(\"  gr truth {} dtype {}\".format(np.max(train_grndtr[0,0]), train_grndtr[0,0].dtype))\n",
    "print(\"prediction {} dtype {}\".format(np.max(predictions_imgs[0,0]), predictions[0,0].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
